from pyspark.sql import SparkSession
from pyspark.sql.functions import col, regexp_replace
from pyspark.sql.types import DoubleType

spark = SparkSession.builder \
    .appName("build_fact_tourism_metrics") \
    .getOrCreate()

# ‡∏≠‡πà‡∏≤‡∏ô processed data
df = spark.read.parquet(
    "s3://aphiwat-tourism-data-lake-dev/processed/tourism_domestic/"
)

# üî• CLEAN + CAST VALUE
fact_df = (
    df
    # ‡∏•‡∏ö comma ‡πÄ‡∏ä‡πà‡∏ô 1,234,567 ‚Üí 1234567
    .withColumn(
        "value_clean",
        regexp_replace(col("value"), ",", "")
    )
    # cast ‡πÄ‡∏õ‡πá‡∏ô double
    .withColumn(
        "value",
        col("value_clean").cast(DoubleType())
    )
    # ‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà cast ‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á
    .filter(col("value").isNotNull())
    .select(
        "year",
        "month",
        "province_eng",
        "variable",
        "value"
    )
)

# ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô curated fact table
fact_df.write \
    .mode("overwrite") \
    .partitionBy("year", "month") \
    .parquet(
        "s3://aphiwat-tourism-data-lake-dev/curated/fact_tourism_metrics/"
    )

spark.stop()